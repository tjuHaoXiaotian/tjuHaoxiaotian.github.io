<!DOCTYPE html>
<!-- saved from url=(0040)http://artemsheludko.pw/flexible-jekyll/ -->
<html lang="en">
    <head>

        <script>
            var _hmt = _hmt || [];
            (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?1833684faf5f254c1bb31386c5780c57";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
            })();
        </script>
        
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <title>Dr. Xiaotian Hao's Homepage</title>
        <meta content="website" property="og:type">
        <meta content="Dr. Xiaotian Hao." property="og:description">
        <meta content="./hxt.png" property="og:image">
        <meta name="description" content="">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
        <meta property="og:image" content="">
        <!-- Chrome, Firefox OS and Opera -->
        <meta name="theme-color" content="#263959">
        <!-- Windows Phone -->
        <meta name="msapplication-navbutton-color" content="#263959">
        <!-- iOS Safari -->
        <meta name="apple-mobile-web-app-status-bar-style" content="#263959">
        <!-- Styles -->
        <link rel="stylesheet" href="./css/main.css">
        <link rel="shortcut icon" href="./hxt.png"  />
    </head>

    <body>

        <div class="wrapper"  >
            <aside class="sidebar" style="overflow:auto;">
                <header >
                    <div class="about" >
                        <div class="cover-author-image">
                            <a href="hxt.png"><img src="hxt.png" alt="Xiaotian Hao"></a>
                        </div>
                        <div class="author-name">Xiaotian Hao</div>
                        <p>I received the B.E. degree from <a href="http://www.tju.edu.cn/">Tianjin University</a> in 2016, and
                            now is a fourth-year Phd student in <a href="http://www.icdai.org/index.html">Deep Reinforcement Learning (DRL) Lab</a>, Tianjin University advised by Jianye Hao.
                            My research interests include <strong>Reinforcement Learning, Multiagent System, and Combinatorial Optimization</strong>.
                        </p>
                        <br>
                        <p style="margin-top: -15pt" >
                            [<a href="#news">News</a>]  
                            [<a href="#pub">Publications</a>] 
                        <!-- </p>
                        
                        <p style="margin-top: -5pt"> -->
                            [<a href="#awards">Awards</a>]
                            [<a href="#link">Others</a>]
                            [<a href="paper/xiaotian_cv.pdf" target="_blank">CV</a>]
                        </p>
                        <p style="margin-top: -0pt" >
                            <a href="https://github.com/tjuHaoXiaotian" target="_blank"><img src="img/github.png" height="25pt" /></a>
                            <a href="https://scholar.google.com/citations?hl=zh-CN&user=xgk9NPwAAAAJ&view_op=list_works&sortby=pubdate" target="_blank" ><img src="img/googlescholar.png" height="25pt" /></a>
                            <a href="https://www.zhihu.com/people/tju-hao-xiao-tian/posts" target="_blank"><img src="img/zhihu.png" height="25pt" /></a>
                        </p>
                    </div>
                    <section class="contact" >
                        <h3 class="contact-title"  style="margin-top: -15pt" >Contact me</h3>
                        <ul>
                            <font size="2" ><strong>Email:</strong></font>
                            <font size="2">xiaotianhao@tju.edu.cn</font>
                            <br>
<!--                            <font size = "2"><strong>Adress:</strong> </font>-->
<!--                            <font size="2">05F, Tencent Beijing Headquarters, Beijing</font>-->
                        </ul>
                    </section>
                    <div style="text-align: center">
                        <a href="http://s01.flagcounter.com/more/Hp">
                            <img src="https://s01.flagcounter.com/count/Hp/bg_FFFFFF/txt_000000/border_CCCCCC/columns_3/maxflags_9/viewers_0/labels_1/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0" style="margin-top: 15px" >
                        </a>
                    </div>
                </header> 

                <!-- <ul> -->
                <!-- <p style="text-align: center; margin-top: -5px"><font size="2" ><strong>Email:</strong></font></p> -->
                <!-- <br> -->
                <!-- <p style="text-align: center; margin-top:-20px;line-height: 15px"><font size="2">xbliu.vmc@pku.edu.cn </font></p> -->
                <!-- <br>  -->
                <!-- <p  style="text-align: center; margin-top:-15px; "><font size = "2"><strong>Adress:</strong> </font></p> -->
                <!-- <br>  -->
                <!-- <p style="text-align: center; margin-top:-20px;line-height: 15px "> <font size="2">Room 2613, No.2 Science Building, Peking University, Beijing, China</font></p> -->
                <!-- </ul> -->

                <!-- </font><br> <font size="2" style="margin-left: 52px">  -->

                <!-- End Section Contact -->
                <!--     <div class="copyright">
                <p>2017 © Xiaotian Hao</p>
                </div> -->
                <!-- </footer>  -->
            </aside> 
            <!-- End Sidebar -->
        </div>



        <div class="content-box clearfix">
            <div id="content-title" >
                <span class="border"></span>
                <span><h2 ><a name="news">News</a></h2></span>
                <span class="border"></span>
            </div>

            <div id = "news-content">
                <li style="margin: -10px 0px -10px 5px" >2023.12.09, <strong style="color:red">3 papers</strong> were accepted by <strong>AAAI-2024</strong>!
                    <ul>
                        <li style="margin: -15px 0px 0px 0px" >(a) Multiagent Gumbel MuZero: Efficient Planning in Combinatorial Action Spaces</li>
                        <li>(b) PORTAL: Automatic Curricula Generation for Multiagent Reinforcement Learning</li>
                        <li>(c) Designing Biological Sequences without Prior Knowledge using Evolutionary Reinforcement Learning</li>
                    </ul>
                </li>
<!--                <li style="margin: 10px 0px 0px 5px" ><strong><font color="red">2020.10.07, I married <a href="https://wencytime.github.io/">Wency</a>!</font></strong></li>-->
                <li style="margin: 20px 0px 0px 5px" >
                    <article class="post">
                        <a class="post-thumbnail" style="background-image: url(./img/DAI23-masce.png)"></a>
                        <div class="post-content">
                            <h2 class="post-title"><strong>Give a talk at DAI 2023</strong></h2>
                            <li style="margin: 10px 0px 10px 15px">On December 1, 2023, I was invited to deliver a presentation at the <a href="https://sites.google.com/view/dai-2023-masce/home">Workshop on Multi-Agent Systems in Complex Environments</a> during the DAI 2023 conference.</li>
                            <li style="margin: 0px 0px 15px 15px"><strong>An enjoyable journey to Singapore.</strong> After the pandemic, it's my first time going abroad for a conference, and I'm fortunate to be invited to give a presentation at the DAI workshop! At the beautiful Nanyang Technological University, there are many cutting-edge viewpoints on MARL, large decision models, agents, robot learning, and open environment RL colliding here. However, the rain in Singapore is a bit too frequent, haha.</li>
                        </div>
                    </article>
                </li>
                <li style="margin: -0px 0px 0px 5px" >2023.07，DataFunTalk社区，分享主题为<a href="https://mp.weixin.qq.com/s/C_bNa42FdR5xLRcbSLXSCg"><strong>《多智能体强化学习大模型初探》 </strong>的学术报告。</a></li>
                <li style="margin: -0px 0px 0px 5px" >2023.01，One paper on multiagent learning accepted by <strong>ICLR 2023</strong>.</li>
                <li style="margin: -0px 0px 0px 5px" >2022.10，I was awarded <strong>Huawei Excellent Intern (Top 3/200)</strong>.</li>
<!--                <li style="margin: 10px 0px 0px 5px" ><strong><font color="red">2020.10.07, I married <a href="https://wencytime.github.io/">Wency</a>!</font></strong></li>-->
            </div>

            <div id="content-title" >
                <span class="border"></span>
                <span><h2 ><a name="work experience">Work Experience</a></h2></span>
                <span class="border"></span>
            </div>

             <article class="post">
                <a class="post-thumbnail" style="background-image: url(./img/noah.png)"></a>
                <div class="post-content">
                    <h2 class="post-title"><strong>华为-诺亚方舟实验室-决策推理研究团队-Research Intern</strong>（2022.01-2023.07）</h2>
                    <li style="margin: 10px 0px 10px 15px"><strong>盘古大模型RLHF优化项目：</strong> (1)负责Reward Model设计与训练，基于ChatGLM LoRA，DeepSpeed搭建训练框架，针对产品线标注数据集，输出测试精度89%的 模型。(2) 提出基于Stochastic Beam Search实现指数空间高效无放回top-k采样，提升样本质量&多样性，提高RAFT效率。(3) <a href="https://zhuanlan.zhihu.com/p/644697081">整理RLHF技术博客。</a></li>
                    <li style="margin: 0px 0px 15px 15px"><strong>高维优化项目：</strong> 针对多智能体系统中状态-动作空间高维难以优化问题，提出结合置换不变性与置换同变性的归纳偏置设计算法，在星际争霸等基准测试环境中取得SOTA性能，研究成果发表在ICLR 2023（第一作者），<a href="https://github.com/tjuHaoXiaotian/pymarl3">开源代码库pymarl3。</a></li>
                </div>
            </article>

             <article class="post">
                <a class="post-thumbnail" style="background-image: url(./img/noah.png)"></a>
                <div class="post-content">
                    <h2 class="post-title"><strong>华为-诺亚方舟实验室-企业智能团队-Algorithm Engineer</strong>（2020.06-2021.06）</h2>
                    <li style="margin: 10px 0px 10px 15px"><strong>自研大规模线性规划求解器项目：</strong> 提出基于最大堆的pricing加速算法，预估变量价值构造最大堆实现高效top-1（入基）检索。在华为供应链多工厂排产等核心业务落地，千万变量线性规划求解时间提速一倍以上，已集成在华为云天筹AI求解器对外发布，该技术被评为华为潜高等级专利，专利公开号：CN115496247A（Idea的提出人和实现者）。</a></li>
                    <li style="margin: 0px 0px 15px 15px"><strong>Dynamic Pickup and Delivery Problems (DPDP)优化项目：</strong> 针对复杂的DPDP组合优化问题，提出基于RL的分层搜索算法，上层负责将在线动态问题切分为静态问题（学习最优切分方式），下层负责静态问题求解，在松山湖制造投递运输系统落地测试，订单超时减少42%，车辆行驶距离减少23%，研究成果发表在NeurIPS 2021（共同第一作者）。</li>
                </div>
            </article>

             <article class="post">
                <a class="post-thumbnail" style="background-image: url(./img/alimama.jpeg)"></a>
                <div class="post-content">
                    <h2 class="post-title"><strong>阿里巴巴集团-阿里妈妈-精准广告团队-Research Intern</strong>（2018.10-2019.10）</h2>
                    <li style="margin: 10px 0px 10px 15px"><strong>多渠道联合的广告序列化投放项目：</strong> 广告精排阶段，研究广告不同投放组合对用户未来行为及价值的影响，建模为动态背包问题（物品价值和成本受投放策略的影响），采用Bilevel优化，并证明最优性。线上A/B test广告主ROI +25%，双十一期间20%流量，ROI +11%，研究成果发表在ICML-2020（第一作者）。</a></li>
                    <li style="margin: 0px 0px 15px 15px"><strong>手淘Banner钻石展位，多智能体锦囊优化项目：</strong> 广告召回阶段，广告主之间的博弈优化，learning算法加速求解大规模b-matching问题，大盘RPM +19%（离线测试），研究成果发表在IJCAI-2020（第一作者）。</li>
                </div>
            </article>

            <div id="content-title" style="margin-top: 15px">
                <span class="border"></span>
                <span><h2><a name="Selected Publications">Selected Publications</a></h2></span>
                <span class="border"></span>
            </div>

            <article class="post">
                <a class="post-thumbnail" style="background-image: url(./img/paper/ma_muzero2.png)"></a>
                <div class="post-content">
                    <h2 class="post-title">Multiagent Gumbel MuZero: Efficient Planning in Combinatorial Action Spaces (AAAI 2024).</h2>
                    <p style="margin-top: -15px"><strong>Xiaotian Hao</strong>, Jianye Hao, Chenjun Xiao, Kai Li, Dong Li.</p>
                    <p style="margin-top: -10px">AlphaZero and MuZero have achieved state-of-the-art (SOTA) performance in a wide range of domains, including board games and robotics, with discrete and continuous action spaces. However, to obtain an improved policy, they often require an excessively large number of simulations, especially for domains with large action spaces. As the simulation budget decreases, their performance drops significantly. In addition, many important real-world applications have combinatorial (or exponential) action spaces, making it infeasible to search directly over all possible actions. In this paper, we extend AlphaZero and MuZero to learn and plan in more complex multiagent Markov decision processes, where the action spaces increase exponentially with the number of agents. Our new algorithms, Multiagent Gumbel AlphaZero and Multiagent Gumbel MuZero, respectively without and with model learning, achieve SOTA performance on typical cooperative multiagent control problems and more challenging StarCraft II benchmarks, while reducing the number of environmental interactions by up to an order of magnitude compared to SOTA model-free approaches. In particular, we significantly improve prior performance when planning with much fewer simulation budgets. We will open-source the code sooner, hoping to accelerate the research of MCTS-based algorithms in wider communities.</p>
                    <p class="post-date" style="margin-top: -10px">
                        AAAI 2024.
                        [<a href="coming soon...">Paper</a>]
                        [<a href="https://github.com/tjuHaoXiaotian/ma_muzero">Code</a>]
                    </p>
                </div>
            </article>

            <article class="post">
                <a class="post-thumbnail" style="background-image: url(./img/paper/iclr23_pi_pe.png)"></a>
                <div class="post-content">
                    <h2 class="post-title">Boosting Multiagent Reinforcement Learning via Permutation Invariant and
Permutation Equivariant Networks (ICLR 2023).</h2>
                    <p style="margin-top: -15px"><strong>Xiaotian Hao</strong>, Jianye Hao, Hangyu Mao, Weixun Wang, Yaodong Yang, Dong Li, Yan Zheng</p>
                    <p style="margin-top: -10px">The state space in Multiagent Reinforcement Learning (MARL) grows exponentially with the agent number. Such a curse of dimensionality results in poor scalability and low sample efficiency, inhibiting MARL for decades. To break this curse, we propose a unified agent permutation framework that exploits the permutation invariance (PI) and permutation equivariance (PE) inductive biases to reduce the multiagent state space. Our insight is that permuting the order of entities in the factored multiagent state space does not change the information. Specifically, we propose two novel implementations: a Dynamic Permutation Network (DPN) and a Hyper Policy Network (HPN). The core idea is to build separate entity-wise PI input and PE output network modules to connect the entity-factored state space and action space in an end-to-end way. DPN achieves such connections by two separate module selection networks, which consistently assign the same input module to the same input entity (guarantee PI) and assign the same output module to the same entity-related output (guarantee PE). To enhance the representation capability, HPN replaces the module selection networks of DPN with hypernetworks to directly generate the corresponding module weights. Extensive experiments in SMAC, SMACv2, Google Research Football, and MPE validate that the proposed methods significantly boost the performance and the learning efficiency of existing MARL algorithms. Remarkably, in SMAC, we achieve 100% win rates in almost all hard and super-hard scenarios (never achieved before).</p>
                    <p class="post-date" style="margin-top: -10px">
                        ICLR 2023.
                        [<a href="./paper/iclr_23.pdf">Paper</a>]
                        [<a href="https://github.com/tjuHaoXiaotian/pymarl3">Code</a>]
                    </p>
                </div>
            </article>

            <article class="post">
                <a class="post-thumbnail" style="background-image: url(./img/paper/nips21_dpdp.png)"></a>
                <div class="post-content">
                    <h2 class="post-title">A Hierarchical Reinforcement Learning Based Optimization Framework for
Large-scale Dynamic Pickup and Delivery Problems (NeurIPS 2021, CCF-A).</h2>
                    <p style="margin-top: -15px">Yi Ma*, <strong>Xiaotian Hao*</strong>, Jianye Hao, Jiawen Lu, Mingxuan Yuan, Zhaopeng Meng</p>
                    <p style="margin-top: -10px">The Dynamic Pickup and Delivery Problem (DPDP) is an essential problem in the logistics domain, which is NP-hard. The objective is to dynamically schedule vehicles among multiple sites to serve the online generated orders such that the overall transportation cost could be minimized. The critical challenge of DPDP is the orders are not known a priori, ie, the orders are dynamically generated in real-time. To address this problem, existing methods partition the overall DPDP into fixed-size sub-problems by caching online generated orders and solve each sub-problem, or on this basis to utilize the predicted future orders to optimize each sub-problem further. However, the solution quality and efficiency of these methods are unsatisfactory, especially when the problem scale is very large. In this paper, we propose a novel hierarchical optimization framework to better solve large-scale DPDPs. Specifically, we design an upper-level agent to dynamically partition the DPDP into a series of sub-problems with different scales to optimize vehicles routes towards globally better solutions. Besides, a lower-level agent is designed to efficiently solve each sub-problem by incorporating the strengths of classical operational research-based methods with reinforcement learning-based policies. To verify the effectiveness of the proposed framework, real historical data is collected from the order dispatching system of Huawei Supply Chain Business Unit and used to build a functional simulator. Extensive offline simulation and online testing conducted on the industrial order dispatching system justify the superior performance of our framework over existing baselines.</p>
                    <p class="post-date" style="margin-top: -10px">
                        NeurIPS 2021.
                        [<a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/c6a01432c8138d46ba39957a8250e027-Abstract.html">Paper</a>]
<!--                        [<a href="">Code</a>]-->
                    </p>
                </div>
            </article>

            <article class="post">
                <a class="post-thumbnail" style="background-image: url(./img/paper/icml20_dkp.png)"></a>
                <div class="post-content">
                    <h2 class="post-title">Dynamic Knapsack Optimization Towards Efficient Multi-Channel Sequential
Advertising (ICML 2020, CCF-A).</h2>
                    <p style="margin-top: -15px"><strong>Xiaotian Hao</strong>, Zhaoqing Peng, Yi Ma, Junqi Jin, Jianye Hao, Rongquan Bai, Chuan Yu, Han
Li, Jian Xu, Kun Gai.</p>
                    <p style="margin-top: -10px">In E-commerce, advertising is essential for merchants to reach their target users. The typical objective is to maximize the advertiser’s cumulative revenue over a period of time under a budget constraint. In real applications, an advertisement (ad) usually needs to be exposed to the same user multiple times until the user finally contributes revenue (eg, places an order). However, existing advertising systems mainly focus on the immediate revenue with single ad exposures, ignoring the contribution of each exposure to the final conversion, thus usually falls into suboptimal solutions. In this paper, we formulate the sequential advertising strategy optimization as a dynamic knapsack problem. We propose a theoretically guaranteed bilevel optimization framework, which significantly reduces the solution space of the original optimization space while ensuring the solution quality. To improve the exploration efficiency of reinforcement learning, we also devise an effective action space reduction approach. Extensive offline and online experiments show the superior performance of our approaches over state-of-the-art baselines in terms of cumulative revenue.</p>
                    <p class="post-date" style="margin-top: -10px">
                        ICML 2020.
                        [<a href="http://proceedings.mlr.press/v119/hao20b/hao20b.pdf">Paper</a>]
                        [<a href="https://github.com/tjuHaoXiaotian/ICML-2020-MSBCB">Code</a>]
                    </p>
                </div>
            </article>

            <article class="post">
                <a class="post-thumbnail" style="background-image: url(./img/paper/ijcai20_bmatching.png)"></a>
                <div class="post-content">
                    <h2 class="post-title">Learning to Accelerate Heuristic Searching for Large-Scale Maximum
Weighted b-Matching Problems in Online Advertising (IJCAI 2020, CCF-A).</h2>
                    <p style="margin-top: -15px"><strong>Xiaotian Hao</strong>, Junqi Jin, Jianye Hao, Jin Li, Weixun Wang, Han
Li, Jian Xu, Kun Gai.</p>
                    <p style="margin-top: -10px">Bipartite b-matching is fundamental in algorithm design, and has been widely applied into economic markets, labor markets, etc. These practical problems usually exhibit two distinct features: large-scale and dynamic, which requires the matching algorithm to be repeatedly executed at regular intervals. However, existing exact and approximate algorithms usually fail in such settings due to either requiring intolerable running time or too much computation resource. To address this issue, we propose NeuSearcher which leverages the knowledge learned from previously instances to solve new problem instances. Specifically, we design a multichannel graph neural network to predict the threshold of the matched edges weights, by which the search region could be significantly reduced. We further propose a parallel heuristic search algorithm to iteratively improve the solution quality until convergence. Experiments on both open and industrial datasets demonstrate that NeuSearcher can speed up 2 to 3 times while achieving exactly the same matching solution compared with the state-of-the-art approximation approaches.</p>
                    <p class="post-date" style="margin-top: -10px">
                        ICML 2020.
                        [<a href="https://arxiv.org/pdf/2005.04355">Paper</a>]
                    </p>
                </div>
            </article>

           <article class="post">
                <a class="post-thumbnail" style="background-image: url(./img/paper/aamas18_GASIL.gif)"></a>
                <div class="post-content">
                    <h2 class="post-title">Independent Generative Adversarial Self-Imitation Learning in Cooperative
Multiagent Systems (AAMAS 2019, CCF-B).</h2>
                    <p style="margin-top: -15px"><strong>Xiaotian Hao</strong>,  Weixun Wang, Jianye Hao, Yaodong Yang.</p>
                    <p style="margin-top: -10px">Many tasks in practice require the collaboration of multiple agents through reinforcement learning. In general, cooperative multiagent reinforcement learning algorithms can be classified into two paradigms: Joint Action Learners (JALs) and Independent Learners (ILs). In many practical applications, agents are unable to observe other agents' actions and rewards, making JALs inapplicable. In this work, we focus on independent learning paradigm in which each agent makes decisions based on its local observations only. However, learning is challenging in independent settings due to the local viewpoints of all agents, which perceive the world as a non-stationary environment due to the concurrently exploring teammates. In this paper, we propose a novel framework called Independent Generative Adversarial Self-Imitation Learning (IGASIL) to address the coordination problems in fully cooperative multiagent environments. To the best of our knowledge, we are the first to combine self-imitation learning with generative adversarial imitation learning (GAIL) and apply it to cooperative multiagent systems. Besides, we put forward a Sub-Curriculum Experience Replay mechanism to pick out the past beneficial experiences as much as possible and accelerate the self-imitation learning process. Evaluations conducted in the testbed of StarCraft unit micromanagement and a commonly adopted benchmark show that our IGASIL produces state-of-the-art results and even outperforms JALs in terms of both convergence speed and final performance..</p>
                    <p class="post-date" style="margin-top: -10px">
                        ICML 2020.
                        [<a href="https://arxiv.org/pdf/1909.11468">Paper</a>]
                        [<a href="https://github.com/tjuHaoXiaotian/GASIL">Code</a>]
                    </p>
                </div>
            </article>


            <div id="content-title" >
                <span class="border"></span>
                <span><h2 ><a name="Patent">Selected Patents</a></h2></span>
                <span class="border"></span>
            </div>

            <div id = "news-content">
                <li style="margin: -0px 0px 0px 5px" >基于最大堆的线性规划 pricing 加速算法. 李希君（华为实习导师），<strong>郝晓田（idea的提出者和实现者）</strong>，袁明轩，郝建业，曾嘉. 公开号：CN115496247A</li>
            </div>

            <div id="content-title" >
                <span class="border"></span>
                <span><h2 ><a name="competitions">Selected Competitions & Awards</a></h2></span>
                <span class="border"></span>
            </div>

            <div id = "news-content">
                <li style="margin: -0px 0px 0px 5px" ><a href="https://zhuanlan.zhihu.com/p/444200395">2021年11月：NeurIPS-2020-MineRL国际竞赛冠军</a></li>
            </div>
            <div id = "news-content">
                <li style="margin: -0px 0px 0px 5px" ><a href="https://github.com/tjuHaoXiaotian/smarts_track2/blob/main/submission/README.md">2021年12月：NeurIPS-2022 SMARTS自动驾驶国际竞赛最佳参赛奖</a></li>
                <video poster="./img/smarts.png" src="./video/smarts.mp4" controls="controls">
                    您的浏览器不支持 video 标签。
                </video>
            </div>
            <div id = "news-content">
                <li style="margin: -0px 0px 0px 5px" ><a href="./img/internet_plus.jpg">2022年8月：互联网 + 创新创业大赛天津赛区银奖</a></li>
            </div>

            <div id = "news-content">
                <li style="margin: -0px 0px 0px 5px" ><a href="./img/hw_excellent_intern.jpg">2022.10：<strong>华为优秀实习生 (Top 3/200)</strong></a></li>
                <li style="margin: -0px 0px 0px 5px" >2019.10：<strong>研究生国家奖学金 (Top 2/100)</strong></li>
            </div>


<!--            <div id="content-title" style="margin-top: -5px">-->
<!--                &lt;!&ndash; <h4><a name="awards">Awards</a></h4> &ndash;&gt;-->
<!--                <p style="margin-top: -10px">-->
<!--                    <li style="margin: -10px 0px 0px 5px" >2020.10, Special Academic Scholarship for Doctor Student of Peking University.</li>-->
<!--                    <li style="margin: 10px 0px 0px 5px" >2020.06, Outstanding member of the Communist Youth League of Peking University.</li>-->
<!--                    <li style="margin: 10px 0px 0px 5px" >2019.09, Special Academic Scholarship for Doctor Student of Peking University.</li>                       -->
<!--                    <li style="margin: 10px 0px 0px 5px" >2018.09, Special Academic Scholarship for Doctor Student of Peking University.</li>-->

<!--                    <li style="margin: 10px 0px 0px 5px" >2018.06, Excellent Talents Scholarship of Cooperative Medianet Innovation Center.</li>-->

<!--                    <li style="margin: 10px 0px 0px 5px" >2016.05, 南开大学创新科研奖励三等奖.</li>-->

<!--                    <li style="margin: 10px 0px 0px 5px" >2016.09, 南开大学优秀军训政工管理干部.</li>-->

<!--                    <li style="margin: 10px 0px 0px 5px" >2015.12, 天津市人民政府奖学金.</li>-->

<!--                    <li style="margin: 10px 0px 0px 5px" >2015.07, 天津市“挑战杯”二等奖（负责人）.</li>-->

<!--                    <li style="margin: 10px 0px 0px 5px" >2015.04, 美国大学生数学建模竞赛M奖（获奖比例9%）.</li>-->

<!--                    <li style="margin: 10px 0px 0px 5px" >2014 11, 南开大学“公能”奖学金.</li>-->

<!--                    <li style="margin: 10px 0px 0px 5px" >2014.05, 南开大学计算机与控制工程学院十佳学生骨干.</li>-->

<!--                    <li style="margin: 10px 0px 0px 5px" >2013.12, 南开大学综合一等奖学金.</li>-->

<!--                    <li style="margin: 10px 0px 0px 5px" >2013.06, 南开大学信息技术科学学院优秀干事.</li>-->

<!--                    <h4><a name="link">Services</a></h4>-->
<!--                    <li style="margin: -10px 0px 0px 5px" >-->
<!--                        I am reviewer of: &lt;!&ndash; IEEE Transactions on Image Processing (T-IP), International Journal of Computer Vision (IJCV), IEEE Transactions on Multimedia (T-MM), IEEE Transactions on Vehicular Technology (T-VT), IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT), IEEE Transactions on Intelligent Transportation Systems (T-ITS), IEEE Journal of Biomedical and Health Informatics (JBHI), IET Computer Vision (IET-CVI), Neurocomputing, Artificial Intelligence Review, Journal of Visual Communication and Image Representation (JVCIR), CVPR 2021-2022, ECCV 2022, AAAI 2020, ISCAS 2020, VCIP 2020. &ndash;&gt;-->
<!--                        <ol style="margin: 0px 0px 0px 0px" reversed="reversed">-->
<!--                            <li>IEEE Transactions on Image Processing (T-IP),</li>-->
<!--                            <li>International Journal of Computer Vision (IJCV),</li>-->
<!--                            <li>IEEE Transactions on Multimedia (T-MM),</li>-->
<!--                            <li>IEEE Transactions on Vehicular Technology (T-VT),</li>-->
<!--                            <li>IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT),</li>-->
<!--                            <li>IEEE Transactions on Intelligent Transportation Systems (T-ITS),</li>-->
<!--                            <li>IEEE Journal of Biomedical and Health Informatics (JBHI),</li>-->
<!--                            <li>IET Computer Vision (IET-CVI),</li>-->
<!--                            <li>Neurocomputing,</li>-->
<!--                            <li>Artificial Intelligence Review,</li>-->
<!--                            <li>Journal of Visual Communication and Image Representation (JVCIR),</li>-->
<!--                            <li>CVPR 2022, 2021,</li>-->
<!--                            <li>ICCV 2023,</li>                            -->
<!--                            <li>ECCV 2022,</li>-->
<!--                            <li>AAAI 2020,</li>-->
<!--                            <li>ISCAS 2020,</li>-->
<!--                            <li>VCIP 2020.</li>-->
<!--                        </ol>-->
<!--                    </li>-->
<!--                    <li style="margin: 10px 0px 0px 5px" > 学生工作：北京大学数字媒体研究所班委、毕业班班长，北京大学信息学院研究生会干事，南开大学软件学院军训副指导员，南开大学计算机与控制工程学院学生会副主席、兼任学术部部长</li>-->
<!--                </p>-->
<!--            </div>-->

            <div id="content-title" style="margin-top: 50px">
                <h3>| Links to my mentors and friends</h3>
                <p style="margin-top: -10px">
                    <a href="http://wwxfromtju.github.io/">Weixun Wang（王维埙）</a>,
                    <a href="https://mayi1996.top/">Yi Ma（马亿）</a>,
                    <a href="https://bluecontra.github.io/">Hongyao Tang（汤宏垚）</a>,
                    <a href="http://cndota.github.io/about/">Yaodong Yang（杨耀东）</a>,
                    <a href="https://fei-ni.github.io/">Fei Ni（倪飞）</a>,
                    <a href="https://yihaiduan.github.io/">Yihai Duan（段义海）</a>,
                    <a href="https://maohangyu.github.io/">Hangyu Mao（毛航宇）</a>,
                    <a href="https://yanzzzzz.github.io/">Yan Zheng（郑岩）</a>,
                    <a href="http://rl.beiyang.ren/">Jianye Hao（郝建业副教授）</a>
                </p>
            </div>

<!--            <div id="content-title" style="margin-top: -15px">-->
<!--                <h4>Impact Factor</h4>-->
<!--                <ul style="margin: -10px 0px 0px 0px" >-->
<!--                    <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI): 24.314</li>-->
<!--                    <li>IEEE Transactions on Image Processing (T-IP): 11.041</li>-->
<!--                    <li>IEEE Transactions on Neural Networks and Learning Systems (T-NNLS): 14.255</li>-->
<!--                    <li>Pattern Recognition (PR): 8.518</li>-->
<!--                    <li>International Journal of Computer Vision (IJCV): 13.369</li>-->
<!--                    <li>IEEE Transactions on Multimedia (T-MM): 8.182</li>-->
<!--                    <li>IEEE Transactions on Intelligent Transportation Systems (T-ITS): 9.551</li>-->
<!--                    <li>IEEE Transactions on Vehicular Technology (T-VT): 6.239</li>-->
<!--                    <li>IEEE Journal of Biomedical and Health Informatics (J-BHI): 7.021</li>-->
<!--                    <li>Neurocomputing: 5.779</li>-->
<!--                    <li>IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT): 5.859</li>-->
<!--                    <li>Computer Vision and Image Understanding (CVIU): 4.886</li>-->
<!--                    <li>Journal of Visual Communication and Image Representation (JVCIR): 2.887</li>-->
<!--                    <li>ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM): 3.275</li>-->
<!--                </ul>-->
<!--            </div>-->

<!--            <div id = "logo" style="margin-top: 10px">-->
<!--                <a href="http://www.tju.edu.cn/"><img  src="img/tju.gif" height="80px" /></a>-->
<!--                <a href="http://www.pku.edu.cn"><img  src="img/pku.png" height="65px" style="margin-left: 50px" /></a>-->
<!--                <a href="http://www.nankai.edu.cn"><img  src="img/nku.jpg" height="65px" style="margin-left: 50px" /></a>-->
<!--            </div>-->
        </div>

    </body>
</html>
